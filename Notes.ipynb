{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer intensive statistical methods\n",
    "\n",
    "\n",
    "- [Rejection Sampling](#rejection-sampling)\n",
    "- [Markov Chain Monte Carlo](#ch-7-markov-chain-monte-carlo)\n",
    "- [Metropolis Hastings](#metropolis-hastings-algorithm-and-why-it-works)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Macros"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ch 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ch 6 - Introduction to the Monte Carlo method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many quantities of interest in inferential statistical analyses can be expressed as the expectation of a function of a random variable, sat $h(X)$.\n",
    "Let $f$ denote the density of $X$ and $\\mu$ denote the expectation of $h(X)$ with respect to $f$. Given an iid random sample $X_1,...,X_n$ from $f$ we can approximate $\\mu$ by a sample average:\n",
    "$$ \\hat{\\mu}_{MC} = \\frac1n \\sum\\limits_{i=1}^{n}h(X_i) \\to \\int h(x)f(x)dx = \\mu $$\n",
    "by the strong law of large numbers. \n",
    "If $h(X)^2$ has finite expectation under $f$ the sampling variance of $\\hat{\\mu}_{MC}$ is $\\sigma^2/n = \\mathrm{E}((h(X)-\\mu)^2/n)$ and we can estimate $\\sigma^2$ by\n",
    "$$ \\hat{Var}(\\hat{\\mu}_{MC}) = \\frac{1}{n-1}\\sum\\limits_{i=1}^n (h(X)-\\hat{\\mu})^2 $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating random samples from familiar distributions using uniform distribution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rejection sampling\n",
    "\n",
    "![Rejection sampling](RejectionSampling.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ch 7. Markov Chain Monte Carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metropolis-Hastings Algorithm and why it works.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very general method for constructing a Markov chain. \n",
    "Say we want to sample from $f$. We can then construct a Markov chain $X$ using the MH algorithm with $f$ as its limiting distribution. Then for large enough $n$ the samples $x_{n}+ ... + x_{n+m}$ is an approximate sample from $f$.\n",
    "\n",
    "\n",
    "> **Theorem:**\n",
    ">     \n",
    ">A Markov chain has a unique limiting distribution  $\\pi(x)$ is the chain is *irreducible*, *aperiodic* and *positive recurrent*.\n",
    ">\n",
    "> If so, the limiting distribution $\\pi(x) = \\lim_{i\\to \\infty} P(X_i = x)$ is given by\n",
    "> $$\\begin{aligned} \\pi(y) &= \\sum_{x\\in S} \\pi(x)P(y|x) & \\text{for all } y\\in S  \\\\\n",
    "    \\sum_{x\\in S} \\pi(x) &= 1 \\tag{1} \\end{aligned} $$\n",
    "\n",
    "A sufficient condition for $(1)$ is the *detailed balance condition*:\n",
    "\n",
    "$$ \\pi(x)P(y|x) = \\pi(y)P(x|y) \\quad \\text{for all } x,y\\in S \\tag{2}$$\n",
    "\n",
    "To see this assume that the detailed balance equation holds, and exchange the summand in the first equation of $(1)$. As the sum is dependent only on $x$, we can factor out $\\pi(y)$. The remaining sum is a conditional density over the entire state space, hence equal to $1$. \n",
    "\n",
    "Markov chains satisfying the *detailed balance equation* are *time-reversible*. \n",
    "\n",
    "In our case the distribution $\\pi(x)$ is given and we want to find $P(y|x)$ such that $(1)$ holds. There are many possible solutions, but we want one good solution. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of the Metropolis Hastings algorithm is to construct a chain satisfying $(1)$, such that the stationary distribution is choosen to be $f(x)$. This is done by ensuring that the detailed balance equation holds, which again is done by a clever choice of acceptance probability. \n",
    "\n",
    "Detailed balance can be re-written as \n",
    "\n",
    "$$ \\frac{f(y|x)}{f(x|y)} = \\frac{f(y)}{f(x)}. \\tag{3}$$ \n",
    "\n",
    "The approach is to separate the transition into two steps, the proposal and the acceptence-rejection. The proposal distribution $g(y|x)$ is the conditional probability of proposing state $y$ given state $x$. The acceptence distribution $A(y,x)$, which is the probability of accepting proposed state $y$. The transition probability can be written as the the product of them:\n",
    "\n",
    "$$ f(y|x) = g(y|x)A(y,x) \\tag{4}$$\n",
    "\n",
    "If we now insert $(4)$ into $(3)$, we obtain a condition $A$ must satisfy in order for detailed balance.\n",
    "\n",
    "$$ \\frac{A(y,x)}{A(x,y)} = \\frac{f(y)g(x|y)}{f(x)g(y|x)} \\tag{5}$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One common choice for $A$ is the Metopolis choce:\n",
    "\n",
    "$$ A(y,x) = \\min\\left(1, \\frac{f(y)g(x|y)}{f(x)g(y|x)} \\right)$$\n",
    "\n",
    "which satisfies $(5)$ since if $f(y)g(x|y) \\geq f(x)g(y|x)$, then\n",
    "$$A(y,x) = 1$$ \n",
    "and \n",
    "$$\\frac{1}{A(x,y)} = \\frac{f(y)g(x|y)}{f(x)g(y|x)}.$$\n",
    "The reversed inequality is similar. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The algorithm\n",
    "\n",
    "In the following $f$ is the target distribution and $g$ is the proposal distribution.\n",
    "\n",
    "> **Metropolis Hastings Algorithm**:\n",
    "> \n",
    "> *Initialize*\n",
    "    >> 1. Pick initial state $x_0$ at random from $g$, s.t $f(x_0)> 0.\n",
    "    >> 2. Set $t = 0$.\n",
    ">\n",
    "> *Iterate*\n",
    ">> 1. Generate a candidate $y$ from proposal distribution $g(y|x_t)$.\n",
    ">> 2. Calculate acceptence probability $A(y,x_t)$.\n",
    ">> 3. *Accept* or *reject*:\n",
    ">>\n",
    ">>> 1. Generate $u \\sim U[0,1]$.\n",
    ">>> 2. If $u \\leq A(y,x_t)$, then *accept* and set $x_{t+1} = y$.\n",
    ">>> 3. Otherwise *reject* and copy the old state forward, $x_{t+1} = x_t$.\n",
    ">>>\n",
    ">> 4. *increment*: Set $t = t+1$.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independence chains\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gibbs sampling\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "name": "R"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
