{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer intensive statistical methods\n",
    "\n",
    "- \n",
    "- "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ch 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ch 6 - Introduction to the Monte Carlo method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many quantities of interest in inferential statistical analyses can be expressed as the expectation of a function of a random variable, sat $\\mathrm{h(X)}$.\n",
    "Let $f$ denote the density of $X$ and $\\mu$ denote the expectation of $h(X)$ with respect to $f$. Given an iid random sample $X_1,...,X_n$ from $f$ we can approximate $\\mu$ by a sample average:\n",
    "$$ \\hat{\\mu}_{MC} = \\frac1n \\sum\\limits_{i=1}^{n}h(X_i) \\to \\int h(x)f(x)dx = \\mu $$\n",
    "by the strong law of large numbers. \n",
    "If $h(X)^2$ has finite expectation under $f$ the sampling variance of $\\hat{\\mu}_{MC}$ is $\\sigma^2/n = \\mathrm{E}((h(X)-\\mu)^2/n)$ and we can estimate $\\sigma^2$ by\n",
    "$$ \\hat{Var}(\\hat{\\mu}_{MC}) = \\frac{1}{n-1}\\sum\\limits_{i=1}^n (h(X)-\\hat{\\mu})^2 $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating random samples from familiar distributions using uniform distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "name": "R"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
