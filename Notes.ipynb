{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer intensive statistical methods\n",
    "\n",
    "\n",
    "- [Rejection Sampling](#rejection-sampling)\n",
    "- [Markov Chain Monte Carlo](#ch-7-markov-chain-monte-carlo)\n",
    "- [Metropolis Hastings](#metropolis-hastings-algorithm-and-why-it-works)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Macros"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ch 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ch 6 - Introduction to the Monte Carlo method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many quantities of interest in inferential statistical analyses can be expressed as the expectation of a function of a random variable, sat $h(X)$.\n",
    "Let $f$ denote the density of $X$ and $\\mu$ denote the expectation of $h(X)$ with respect to $f$. Given an iid random sample $X_1,...,X_n$ from $f$ we can approximate $\\mu$ by a sample average:\n",
    "$$ \\hat{\\mu}_{MC} = \\frac1n \\sum\\limits_{i=1}^{n}h(X_i) \\to \\int h(x)f(x)dx = \\mu $$\n",
    "by the strong law of large numbers. \n",
    "If $h(X)^2$ has finite expectation under $f$ the sampling variance of $\\hat{\\mu}_{MC}$ is $\\sigma^2/n = \\mathrm{E}((h(X)-\\mu)^2/n)$ and we can estimate $\\sigma^2$ by\n",
    "$$ \\hat{Var}(\\hat{\\mu}_{MC}) = \\frac{1}{n-1}\\sum\\limits_{i=1}^n (h(X)-\\hat{\\mu})^2 $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating random samples from familiar distributions using uniform distribution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rejection sampling\n",
    "\n",
    "![Rejection sampling](RejectionSampling.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ch 7. Markov Chain Monte Carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metropolis-Hastings Algorithm and why it works.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very general method for constructing a Markov chain. \n",
    "Say we want to sample from $f$. We can then construct a Markov chain $X$ using the MH algorithm with $f$ as its limiting distribution. Then for large enough $n$ the samples $x_{n}+ ... + x_{n+m}$ is an approximate sample from $f$.\n",
    "\n",
    "\n",
    "> **Theorem:**\n",
    ">     \n",
    ">A Markov chain has a unique limiting distribution  $\\pi(x)$ is the chain is *irreducible*, *aperiodic* and *positive recurrent*.\n",
    ">\n",
    "> If so, the limiting distribution $\\pi(x) = \\lim_{i\\to \\infty} P(X_i = x)$ is given by\n",
    "> $$\\begin{aligned} \\pi(y) &= \\sum_{x\\in S} \\pi(x)P(y|x) & \\text{for all } y\\in S  \\\\\n",
    "    \\sum_{x\\in S} \\pi(x) &= 1 \\tag{1} \\end{aligned} $$\n",
    "\n",
    "A sufficient condition for $(1)$ is the *detailed balance condition*:\n",
    "\n",
    "$$ \\pi(x)P(y|x) = \\pi(y)P(x|y) \\quad \\text{for all } x,y\\in S \\tag{2}$$\n",
    "\n",
    "To see this assume that the detailed balance equation holds, and exchange the summand in the first equation of $(1)$. As the sum is dependent only on $x$, we can factor out $\\pi(y)$. The remaining sum is a conditional density over the entire state space, hence equal to $1$. \n",
    "\n",
    "Markov chains satisfying the *detailed balance equation* are *time-reversible*. \n",
    "\n",
    "In our case the distribution $\\pi(x)$ is given and we want to find $P(y|x)$ such that $(1)$ holds. There are many possible solutions, but we want one good solution. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of the Metropolis Hastings algorithm is to construct a chain satisfying $(1)$, such that the stationary distribution is choosen to be $f(x)$. This is done by ensuring that the detailed balance equation holds, which again is done by a clever choice of acceptance probability. \n",
    "\n",
    "Detailed balance can be re-written as \n",
    "\n",
    "$$ \\frac{f(y|x)}{f(x|y)} = \\frac{f(y)}{f(x)}. \\tag{3}$$ \n",
    "\n",
    "The approach is to separate the transition into two steps, the proposal and the acceptence-rejection. The proposal distribution $g(y|x)$ is the conditional probability of proposing state $y$ given state $x$. The acceptence distribution $A(y,x)$, which is the probability of accepting proposed state $y$. The transition probability can be written as the the product of them:\n",
    "\n",
    "$$ f(y|x) = g(y|x)A(y,x) \\tag{4}$$\n",
    "\n",
    "If we now insert $(4)$ into $(3)$, we obtain a condition $A$ must satisfy in order for detailed balance.\n",
    "\n",
    "$$ \\frac{A(y,x)}{A(x,y)} = \\frac{f(y)g(x|y)}{f(x)g(y|x)} \\tag{5}$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One common choice for $A$ is the Metropolis choce:\n",
    "\n",
    "$$ A(y,x) = \\min\\left(1, \\frac{f(y)g(x|y)}{f(x)g(y|x)} \\right)$$\n",
    "\n",
    "which satisfies $(5)$ since if $f(y)g(x|y) \\geq f(x)g(y|x)$, then\n",
    "$$A(y,x) = 1$$ \n",
    "and \n",
    "$$\\frac{1}{A(x,y)} = \\frac{f(y)g(x|y)}{f(x)g(y|x)}.$$\n",
    "The reversed inequality is similar. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The algorithm\n",
    "\n",
    "In the following $f$ is the target distribution and $g$ is the proposal distribution.\n",
    "\n",
    "> **Metropolis Hastings Algorithm**:\n",
    "> \n",
    "> *Initialize*\n",
    "    >> 1. Pick initial state $x_0$ at random from $g$, s.t $f(x_0)> 0.\n",
    "    >> 2. Set $t = 0$.\n",
    ">\n",
    "> *Iterate*\n",
    ">> 1. Generate a candidate $y$ from proposal distribution $g(y|x_t)$.\n",
    ">> 2. Calculate acceptence probability $A(y,x_t)$.\n",
    ">> 3. *Accept* or *reject*:\n",
    ">>\n",
    ">>> 1. Generate $u \\sim U[0,1]$.\n",
    ">>> 2. If $u \\leq A(y,x_t)$, then *accept* and set $x_{t+1} = y$.\n",
    ">>> 3. Otherwise *reject* and copy the old state forward, $x_{t+1} = x_t$.\n",
    ">>>\n",
    ">> 4. *increment*: Set $t = t+1$.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independence chains\n",
    "\n",
    "Similar to importance sampling. $g(y | x_{i-1}) = g(y)$. $g$ is an approximation to $\\pi$, hence the acceptace rate should be high. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metropolis algorithm\n",
    "\n",
    "When the proposal density is symmetric around the current value. $g(x_{i-1} | y ) = g(y | x_{i-1})$. Acceptance rates should be between $20\\%$ and $50\\%$.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gibbs sampling\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional densities\n",
    "\n",
    "*Notation*. $x^{(-j)}$ is the vector $x$ with the $j$'th coordinate omitted.\n",
    "\n",
    "The full conditional densities $\\pi(x^j | x^{(-j)}), j = 1,...,p,$ and the joint density $\\pi(x)$ are related as follows:\n",
    "\n",
    "$$ \\pi(x^j | x^{(-j)}) = \\frac{\\pi(x)}{\\pi(x^{(-j)})}  \\propto \\pi(x)$$\n",
    "\n",
    "Thus the non-normalized conditional densities of $x^j|x^{(-j)}$ can be directly derived from $\\pi(x)$ by omitting all multiplicative factors, that do not depend on $x^j$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The algorithm\n",
    "\n",
    "The idea of Gibbs sampling is to sequentially sample from univariate conditional distributions.\n",
    "A special case of the MH- algorithm.\n",
    "\n",
    "> **Gibbs Sampling Algorithm**\n",
    ">\n",
    "> 1. Select strting values $x_0$ and set $i=0$.\n",
    "> 2. Repeatedly:\n",
    ">\n",
    ">> Sample $x_{i+1}^{1}|\\cdot \\sim \\pi(x^{1}|x_{i}^{2},... x_{i}^{p}) $\n",
    ">>\n",
    ">> Sample $x_{i+1}^{2}|\\cdot \\sim \\pi(x^{2}|x_{i+1}^{1}, x_{i}^{3},... x_{i}^{p})$\n",
    ">>\n",
    ">> $\\vdots$\n",
    ">>\n",
    ">> Sample $x_{i+1}^{p-1}|\\cdot \\sim \\pi(x^{p-1}|x_{i+1}^{1},x_{i+1}^{2}, ... , x_{i+1}^{p-2}, x_{i}^{p})$\n",
    ">>\n",
    ">> Sample $x_{i+1}^{p}|\\cdot \\sim \\pi(x^{p}|x_{i+1}^{1},... x_{i+1}^{p-1})$\n",
    ">>\n",
    "> 3. Increment $i$ and go to step 2.\n",
    "\n",
    "Here $|\\cdot$ denotes conditioning on the most recent updates of all other elements of $x$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Conjugate gamma-Poisson hirarchical model.\n",
    "\n",
    "* $y_i$ number of failiures of pump $i$.\n",
    "* $t_i$ length of operation time of pump $i$. (in kilo hours)\n",
    "\n",
    "**Model**:\n",
    "$$ y_i|\\lambda_i \\sim Po(\\lambda_i t_i)$$\n",
    "\n",
    "**Conjugate prior for $\\lambda_i$:**\n",
    "$$ \\lambda_i | \\alpha,\\beta\\sim G(\\alpha, \\beta)$$\n",
    "\n",
    "**Hyper-prior on $\\alpha$ and $\\beta$:**\n",
    "$$ \\alpha \\sim Exp(1.0) \\quad \\beta \\sim G(0.1,10.0)$$\n",
    "\n",
    "The posterior of the $12$ parameters $(\\alpha, \\beta, \\lambda_1,..., \\lambda_{10})$ given $y_1,...,y_{10}$ is proportional to\n",
    "\n",
    "$$\\pi(\\alpha, \\beta, \\lambda_1,..., \\lambda_{10}|y_1,...,y_{10}) \\propto \\pi(\\alpha) \\pi(\\beta) \\prod_{i=1}^{10} [\\pi(\\lambda_i | \\alpha, \\beta) \\pi(y_i|\\lambda_i)]$$\n",
    "\n",
    "$$ \n",
    "\\propto \n",
    "\\underbrace{e^{-\\alpha}}_{\\text{Prior on }\\alpha}\n",
    "\n",
    "\\overbrace{\\beta^{0.1-1}e^{-10\\beta}}^{\\text{Prior on } \\beta}\n",
    "\\underbrace{\\left[ \\prod_{i=1}^{10} \\exp(-\\lambda_i t_i)\\lambda_i^{y_i} \\right]}_{\\text{Likelihood}}\n",
    "\\overbrace{\\left[ \\prod_{i=1}^{10} \\exp(-\\beta\\lambda_i) \\lambda_i^{\\alpha-1} \\right]\n",
    "\\left[ \\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)}\\right]^{10}}^{\\text{Conjugate prior}}\n",
    "$$\n",
    "\n",
    "$$ = \n",
    "\\left( \\frac{\\beta^{\\alpha} e^{-\\beta}}{\\Gamma(\\alpha)} \\right)^{10} e^{-\\alpha} \\beta^{-0.9}\n",
    "\\exp\\left( -\\sum_{i=1}^{10} \\lambda_i(t_i+\\beta) \\right) \\prod_{i=1}^{10}\\lambda_i^{y_i+\\alpha-1}\n",
    "$$\n",
    "\n",
    "*Not sure how to obtain closed form expression here*\n",
    "\n",
    "$$\n",
    "\\pi(\\lambda_i |...) \\propto \\exp(-\\lambda_i(t_i+\\beta))\\lambda_i^{y_i+\\alpha-1}\n",
    "$$\n",
    "Gamma dist.\n",
    "\n",
    "$$\n",
    "\\pi(\\beta |...) \\propto \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "name": "R"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
