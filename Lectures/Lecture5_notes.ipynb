{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of module 1\n",
    "\n",
    "Importance sampling: More about estimation of expectations\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monte carlo integration\n",
    "\n",
    "Analytic solution is best when possible. Might not be easy.\n",
    "Assumtion: Easy to sample from $f$. \n",
    "A monte carlo estimate is is the sample mean. Unbiased.\n",
    "Strong law of larege numbers assures convergence a.s to the expected value.\n",
    "\n",
    "Failiure of independence will alter the variance. The accuracy of the MC estimate will be reduced if the samples are positively correlated. Increase if neg. correlated.\n",
    "\n",
    "MC integration can be used for any function $h(\\dot)$. Setting $h = I_A$ to estimate $P(A)$.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rejection samling\n",
    "\n",
    "want $x\\sim f(x)$ \n",
    "Know how to gen from $g(x)$\n",
    "Know $c> 1$ so $f(x)/g(x)\\leq c$ for all $x$\n",
    "Alg: \n",
    "\n",
    "Overall acceptence prob is $1/c$, numbers of generated samples per accepted sample: $c$.\n",
    "Dont need to know the normalizing constant\n",
    "Often not efficient in high dimentions\n",
    "\n",
    "Difficulties:\n",
    "- Find the constant $c \\to$ Sample importance resampling (weighted resampling)\n",
    "- Find a good proposal dist $\\to$ adaptive importance sampling. (Less important for this class)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importance sampling\n",
    "\n",
    "Approximation of expectations. Does not provide a mechanism for drawing samples for a distribution. \n",
    "\n",
    "Idea\n",
    "\n",
    "*wrote stuff on paper* Reweighing technique\n",
    "\n",
    "Def $\\hat{\\mu}_{IS}$ \n",
    "\n",
    "need that the support of $g$ contains the support of $f$. $w(x_i)$ are importance weights.\n",
    "\n",
    "Need to know the normalizing constant of $f$ and $g$, when not possible we need to reweigh. \n",
    "\n",
    "Can use this to reduce the variance of MCI. If we can choose the right $g$. \n",
    "Importance sampling can help \"focus\" the sampler in the correct area. \n",
    "\n",
    "Difference of $\\hat{\\mu}_{IS}$ and $\\tilde{\\mu}_{IS}$ (Self-normalizing)\n",
    "\n",
    "The performace of IS depends crucially on how well $g$ matches $f$, as with rejection sampling. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayesian concept\n",
    "\n",
    "Providing a mathematical rule of how you are changing your beliefs in ligth of new data. Allows to combine new data with their existing expertise or knowledge.\n",
    "\n",
    "** Bayes Theorem **\n",
    "Relies on the asymmetry of the definition of conditional probalility.\n",
    "\n",
    "$$ P(A|B)= \\frac{P(A)P(B|A)}{P(B)} $$\n",
    "\n",
    "Can be combined with the law of total probablity to split up the denominator.\n",
    "\n",
    "$ P(A_i)$ *prior* probalilities.\n",
    "$P(A_i|B)$ *posterior* probabilities \n",
    "\n",
    "General formulation in terms of densities.\n",
    "\n",
    "In Bayestian statistics parameters are also stochastic variables. The likelihood of $X$ is seen as a conditional probability.\n",
    "\n",
    "#### Posterior distribution\n",
    "\n",
    "$X=x$ observed\n",
    "$X|\\theta \\sim f(x|\\theta)$ [likelihood model]\n",
    "$\\theta \\sim f(\\theta)$ [Prior model]\n",
    "\n",
    "Def posterior distribution. Most important quantity in Bayesian inference. I contains all information about the unknown parameter given the observed value $x$.\n",
    "\n",
    "The posterior is proportional to the likelihood times the prior.\n",
    "\n",
    "*Wrote stuff on paper* Ex binom experiment.\n",
    "\n",
    "#### Point estimates\n",
    "\n",
    "Suitable point estimates are location parameters. Post mean, mode, median. \n",
    "\n",
    "#### Credible intervals\n",
    "\n",
    "Def\n",
    "\n",
    "Infintely many credible intervals for each credible level, at least if continious.\n",
    "\n",
    "Equal tailed credible intervals is a solution.\n",
    "\n",
    "#### Highest posterior density interval.\n",
    "\n",
    "The smalles width interval that contains the probabilities required. Smallest credible intervals. \n",
    "\n",
    "#### Inference\n",
    "\n",
    "All inference is based on the posterior distribution.\n",
    "\n",
    "#### Bayesian Learning\n",
    "\n",
    "Consisten processing of sequentially arising data.\n",
    "Getting all data at once and sequentially updating results in the same posterior.\n",
    "\n",
    "#### Conjugate priors\n",
    "\n",
    "Prior dist incorporate prior beliefs. Pragmatic approach is to choose a conjugate prior dist.\n",
    "\n",
    "Sufficient to study conjucacy for one observation. Stay in the same dist when updating.\n",
    "\n",
    "Makes it easy to fint normalizing constants.\n",
    "\n",
    "\n",
    "#### Improper prior distribution\n",
    "\n",
    "Improper because they do not integrate to $1$.\n",
    "\n",
    "Can result in improper posteriors. Can make model selection difficult.\n",
    "\n",
    "#### Uninformative priors\n",
    "\n",
    "Do not strongly influence the posterior distribution.\n",
    "\n",
    "Historical approach to assign flat priors. Not invariant to bijective transformations\n",
    "\n",
    "#### Jeffreys Priors\n",
    "\n",
    "$p(\\theta) \\propto \\sqrt{J(\\theta)}$ \n",
    "\n",
    "$J$ is the Fisher information matrix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "name": "R"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
